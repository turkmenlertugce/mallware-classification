{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's do importations\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV,train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import GenericUnivariateSelect\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Virtual</th>\n",
       "      <th>Offset</th>\n",
       "      <th>loc</th>\n",
       "      <th>Import</th>\n",
       "      <th>Imports</th>\n",
       "      <th>var</th>\n",
       "      <th>Forwarder</th>\n",
       "      <th>UINT</th>\n",
       "      <th>LONG</th>\n",
       "      <th>BOOL</th>\n",
       "      <th>...</th>\n",
       "      <th>Img99</th>\n",
       "      <th>Img100</th>\n",
       "      <th>Img101</th>\n",
       "      <th>Img102</th>\n",
       "      <th>Img103</th>\n",
       "      <th>Img104</th>\n",
       "      <th>Img105</th>\n",
       "      <th>Img106</th>\n",
       "      <th>Img107</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-208196.847822</td>\n",
       "      <td>149454.443336</td>\n",
       "      <td>330552.774213</td>\n",
       "      <td>133907.410063</td>\n",
       "      <td>44038.800343</td>\n",
       "      <td>55156.067737</td>\n",
       "      <td>-77588.974897</td>\n",
       "      <td>171979.000000</td>\n",
       "      <td>162674.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1574.0</td>\n",
       "      <td>8640.382774</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>36209.864030</td>\n",
       "      <td>221318.549792</td>\n",
       "      <td>-1568.194718</td>\n",
       "      <td>22651.037591</td>\n",
       "      <td>-144906.975987</td>\n",
       "      <td>-33489.566102</td>\n",
       "      <td>157701.356695</td>\n",
       "      <td>7702.000000</td>\n",
       "      <td>6551.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2796.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>88398.670923</td>\n",
       "      <td>66550.556919</td>\n",
       "      <td>5404.362294</td>\n",
       "      <td>13947.925003</td>\n",
       "      <td>-48559.885445</td>\n",
       "      <td>257023.562444</td>\n",
       "      <td>-204889.973046</td>\n",
       "      <td>151324.169975</td>\n",
       "      <td>12946.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>2726.071722</td>\n",
       "      <td>9.0</td>\n",
       "      <td>615.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>98583.277889</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-157101.258148</td>\n",
       "      <td>-60336.395075</td>\n",
       "      <td>157629.928962</td>\n",
       "      <td>117458.409503</td>\n",
       "      <td>62076.273381</td>\n",
       "      <td>98733.489947</td>\n",
       "      <td>-51461.636374</td>\n",
       "      <td>122247.000000</td>\n",
       "      <td>98621.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>91945.635853</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32595.648968</td>\n",
       "      <td>-228909.737896</td>\n",
       "      <td>-87033.363460</td>\n",
       "      <td>131606.196188</td>\n",
       "      <td>-118625.690367</td>\n",
       "      <td>89326.297602</td>\n",
       "      <td>-84991.427204</td>\n",
       "      <td>15501.000000</td>\n",
       "      <td>11864.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-73364.892264</td>\n",
       "      <td>56908.607312</td>\n",
       "      <td>17895.279817</td>\n",
       "      <td>-4589.198675</td>\n",
       "      <td>103618.354421</td>\n",
       "      <td>-126164.290238</td>\n",
       "      <td>-24272.971224</td>\n",
       "      <td>7100.000000</td>\n",
       "      <td>6002.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84772.903087</td>\n",
       "      <td>...</td>\n",
       "      <td>-91323.369562</td>\n",
       "      <td>101628.992660</td>\n",
       "      <td>8812.429736</td>\n",
       "      <td>-41149.748369</td>\n",
       "      <td>-56293.578460</td>\n",
       "      <td>87524.257112</td>\n",
       "      <td>-200433.940978</td>\n",
       "      <td>69304.000000</td>\n",
       "      <td>65638.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26135.603443</td>\n",
       "      <td>172273.939349</td>\n",
       "      <td>74515.593674</td>\n",
       "      <td>79555.659907</td>\n",
       "      <td>79230.809864</td>\n",
       "      <td>92047.004360</td>\n",
       "      <td>94829.356066</td>\n",
       "      <td>71789.000000</td>\n",
       "      <td>68354.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-70335.106256</td>\n",
       "      <td>-21680.148668</td>\n",
       "      <td>11900.591113</td>\n",
       "      <td>8015.793354</td>\n",
       "      <td>-105036.351181</td>\n",
       "      <td>-33386.286236</td>\n",
       "      <td>169699.674511</td>\n",
       "      <td>89989.000000</td>\n",
       "      <td>70139.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>61033.550970</td>\n",
       "      <td>...</td>\n",
       "      <td>-14702.601507</td>\n",
       "      <td>18593.024103</td>\n",
       "      <td>2249.256720</td>\n",
       "      <td>45713.524900</td>\n",
       "      <td>-16239.518388</td>\n",
       "      <td>-78553.054374</td>\n",
       "      <td>-115903.637264</td>\n",
       "      <td>9394.000000</td>\n",
       "      <td>3145.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4999 rows × 1805 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Virtual  Offset     loc       Import  Imports     var     Forwarder  \\\n",
       "0         3.0     3.0   689.0    18.000000      6.0   890.0      6.000000   \n",
       "1         3.0     3.0   583.0    15.000000      5.0  1574.0   8640.382774   \n",
       "2         3.0     4.0  2796.0    15.000000      5.0   625.0      5.000000   \n",
       "3         3.0     3.0   373.0  2726.071722      9.0   615.0      9.000000   \n",
       "4         3.0     3.0    77.0    12.000000      4.0    66.0  91945.635853   \n",
       "...       ...     ...     ...          ...      ...     ...           ...   \n",
       "4994      4.0     4.0   118.0     0.000000      3.0     0.0      0.000000   \n",
       "4995      3.0     3.0    27.0    12.000000      4.0    38.0      4.000000   \n",
       "4996      3.0     3.0    16.0    12.000000      4.0     7.0      4.000000   \n",
       "4997      4.0     4.0  2810.0     0.000000      2.0   666.0      0.000000   \n",
       "4998      3.0     4.0  1587.0    21.000000      7.0   526.0      7.000000   \n",
       "\n",
       "      UINT          LONG          BOOL  ...          Img99         Img100  \\\n",
       "0     39.0     17.000000     88.000000  ... -208196.847822  149454.443336   \n",
       "1      6.0      7.000000     30.000000  ...   36209.864030  221318.549792   \n",
       "2     58.0     11.000000    152.000000  ...   88398.670923   66550.556919   \n",
       "3     16.0  98583.277889     34.000000  ... -157101.258148  -60336.395075   \n",
       "4      3.0      0.000000      5.000000  ...   32595.648968 -228909.737896   \n",
       "...    ...           ...           ...  ...            ...            ...   \n",
       "4994   7.0      0.000000     19.000000  ...  -73364.892264   56908.607312   \n",
       "4995   3.0      0.000000  84772.903087  ...  -91323.369562  101628.992660   \n",
       "4996   9.0      0.000000     16.000000  ...   26135.603443  172273.939349   \n",
       "4997  14.0      9.000000     26.000000  ...  -70335.106256  -21680.148668   \n",
       "4998  34.0      5.000000  61033.550970  ...  -14702.601507   18593.024103   \n",
       "\n",
       "             Img101         Img102         Img103         Img104  \\\n",
       "0     330552.774213  133907.410063   44038.800343   55156.067737   \n",
       "1      -1568.194718   22651.037591 -144906.975987  -33489.566102   \n",
       "2       5404.362294   13947.925003  -48559.885445  257023.562444   \n",
       "3     157629.928962  117458.409503   62076.273381   98733.489947   \n",
       "4     -87033.363460  131606.196188 -118625.690367   89326.297602   \n",
       "...             ...            ...            ...            ...   \n",
       "4994   17895.279817   -4589.198675  103618.354421 -126164.290238   \n",
       "4995    8812.429736  -41149.748369  -56293.578460   87524.257112   \n",
       "4996   74515.593674   79555.659907   79230.809864   92047.004360   \n",
       "4997   11900.591113    8015.793354 -105036.351181  -33386.286236   \n",
       "4998    2249.256720   45713.524900  -16239.518388  -78553.054374   \n",
       "\n",
       "             Img105         Img106    Img107  target  \n",
       "0     -77588.974897  171979.000000  162674.0       2  \n",
       "1     157701.356695    7702.000000    6551.0       8  \n",
       "2    -204889.973046  151324.169975   12946.0       6  \n",
       "3     -51461.636374  122247.000000   98621.0       4  \n",
       "4     -84991.427204   15501.000000   11864.0       1  \n",
       "...             ...            ...       ...     ...  \n",
       "4994  -24272.971224    7100.000000    6002.0       4  \n",
       "4995 -200433.940978   69304.000000   65638.0       3  \n",
       "4996   94829.356066   71789.000000   68354.0       3  \n",
       "4997  169699.674511   89989.000000   70139.0       2  \n",
       "4998 -115903.637264    9394.000000    3145.0       9  \n",
       "\n",
       "[4999 rows x 1805 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get the dataset and display it\n",
    "df = pd.read_csv(\"C:/Users/TUGCE/Downloads/hw5_data.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and test set with shuffling\n",
    "train_df, test_df = train_test_split(df,random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score:  0.6624\n"
     ]
    }
   ],
   "source": [
    "#Create an instance of the class Decision Tree Classifier, which will represent the decision tree\n",
    "#I made max_depth = 3 to make test score small\n",
    "tree = DecisionTreeClassifier(max_depth=3)\n",
    "tree.fit(train_df.drop('target', axis=1), train_df['target'])  \n",
    "print('Test set score: ', accuracy_score(test_df['target'], tree.predict(test_df.drop('target',axis=1))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increace accuracy, using validation set instead of test set can help. One way of doing is by using cross validation. In cross validation, we will choose **k** folds, which is the number of slices we create in our dataset. We then take turns using all but one of the k folds to train on, and evaluate on the held out fold. We repeat this k times, holding out each fold once. I will apply cross validation to all classification methods that ı am evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores:  [0.69333333 0.65866667 0.624      0.65066667 0.65287049]\n",
      "Avg Acc:  0.6559074321317311  std dev:  0.022194973742432463  max:  0.6933333333333334\n"
     ]
    }
   ],
   "source": [
    "#Define a method for esminating cross validation score \n",
    "#I took k as 5 for k fold cross validation in all the k fold cross validation computations\n",
    "def cross_val(class_algorithm):    \n",
    "    scores = cross_val_score(class_algorithm, train_df.drop('target', axis=1), train_df['target'], cv=5)\n",
    "    print(\"Cross validation scores: \", scores)\n",
    "    print(\"Avg Acc: \" , scores.mean() , \" std dev: \", scores.std(), \" max: \", scores.max())\n",
    "#Estimate cross validation computations for decision tree\n",
    "cross_val(tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that using cross validation does help. But what about reducing the number of useless features?. This is called feature selection. Because in our dataset we have 1804 features. This is a lot. We can try different number of features and choose the one with the best cross validation score. By that way, after using feature selection we can also use cross validation and improve accuracy even more. I will apply feature selection to all classification methods that I am evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree (and also random forest) already has a embedded feature selection method (feature importances)\n",
    "##Define a method for calculating embedded feature selection\n",
    "#Because it takes lots of time to run the code I am not iterating through every possible number of features\n",
    "def feature_select_embedded (class_algorithm, new_classifier,class_name):\n",
    "    ks = [i for i in range(2, df.drop('target',axis=1).shape[1],400)]\n",
    "    arr = []\n",
    "    for k in ks:\n",
    "        features = []\n",
    "        for importance, name in sorted(zip(class_algorithm.feature_importances_, df.drop('target',axis=1).columns),reverse=True)[:k]:\n",
    "            features.append(name)\n",
    "        x_feature = train_df[features]\n",
    "        classifier_new = new_classifier\n",
    "        score = cross_val_score(classifier_new, x_feature, train_df['target'], cv=5)\n",
    "        print(f\"For {k} Features {class_name} Mean Accuracy: \", score.mean())\n",
    "        arr.append(score.mean())\n",
    "    arr.sort(reverse=True)\n",
    "    print(\"Highest score value:\",arr[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that without feature selection mean cross validation score was 0.6553740987983978. Morever, with feature selection best mean cross validation score is 0.6556407654650644 which has feature value of 1602. It doesn't increase drastically. It is good to remember that because of running time it is not possible to iterate through every possible values of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 2 Features Decision Tree Mean Accuracy:  0.5993612817089453\n",
      "For 402 Features Decision Tree Mean Accuracy:  0.6505733867378727\n",
      "For 802 Features Decision Tree Mean Accuracy:  0.6505744548286604\n",
      "For 1202 Features Decision Tree Mean Accuracy:  0.6500411214953271\n",
      "For 1602 Features Decision Tree Mean Accuracy:  0.6564407654650645\n",
      "Highest score value: 0.6564407654650645\n"
     ]
    }
   ],
   "source": [
    "#Call the feature selection method\n",
    "new_class = DecisionTreeClassifier(max_depth=3)\n",
    "dec_tree = \"Decision Tree\"\n",
    "feature_select_embedded(tree,new_class,dec_tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, hyperparameter tunning (finding best parameter) can increase score even more by applying grid search. I will apply hyperparameter tunning to all classification methods that I am evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(max_depth=3),\n",
       "             param_grid=[{&#x27;max_depth&#x27;: [3, 5, 9, 15]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(max_depth=3),\n",
       "             param_grid=[{&#x27;max_depth&#x27;: [3, 5, 9, 15]}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(max_depth=3),\n",
       "             param_grid=[{'max_depth': [3, 5, 9, 15]}])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#By finding the best feature value calculate new training and test data and fit train data into the instance of Grid Search class\n",
    "features = []\n",
    "for importance, name in sorted(zip(tree.feature_importances_, df.drop('target',axis=1).columns),reverse=True)[:1602]:\n",
    "    features.append(name)\n",
    "x_feature = train_df[features]\n",
    "x_feature_test = test_df[features]\n",
    "#Apply grid search to find best hyperparameter, (because it takes lots of time to run the code I am just using max depth parameter)\n",
    "param_grid = [\n",
    "  {\n",
    "   'max_depth': [ 3, 5, 9, 15]\n",
    "   },\n",
    " ]\n",
    "clf = GridSearchCV(new_class, param_grid, cv=5)   \n",
    "clf.fit(x_feature, train_df['target'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, test set score was 0.6624 but now it is 0.86 by using the max depth = 9. It improved the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter for 5 fold cross validation: {'max_depth': 9}\n",
      "Best score for a 5 fold cross validation: 0.8375562082777035\n",
      "Test set score after CV:  0.8624\n"
     ]
    }
   ],
   "source": [
    "print('Best parameter for 5 fold cross validation:',clf.best_params_)\n",
    "print('Best score for a 5 fold cross validation:',clf.best_score_)\n",
    "print('Test set score after CV: ', accuracy_score(test_df['target'],clf.predict(x_feature_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score:  0.9064\n"
     ]
    }
   ],
   "source": [
    "#Create an instance of the class Decision Random Forest Classifier, which will represent the random forest classification\n",
    "#But with random forest even though I try different n_estimators values the test score was always near 0.90\n",
    "#This is much bigger than deicison tree's test score. TOne of the reasons it uses ensembling.It makes test score higher\n",
    "ran_for=RandomForestClassifier(n_estimators=40)\n",
    "ran_for.fit(train_df.drop('target', axis=1), train_df['target']) \n",
    "print('Test set score: ', accuracy_score(test_df['target'], ran_for.predict(test_df.drop('target',axis=1))))  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that using cross validation does help again.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores:  [0.912      0.89733333 0.888      0.90533333 0.90520694]\n",
      "Avg Acc:  0.9015747218513575  std dev:  0.008225193762418623  max:  0.912\n"
     ]
    }
   ],
   "source": [
    "cross_val(ran_for)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that without feature selection mean cross validation score was 0.9015747218513575. Morever, with feature selection best mean cross validation score is 0.90424281263907454 which has feature value of 402. It doesn't increase drastically. It is good to remember that because of running time it is not possible to iterate through every possible values of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 2 Features Random Forest Mean Accuracy:  0.7572713840676457\n",
      "For 402 Features Random Forest Mean Accuracy:  0.9042428126390745\n",
      "For 802 Features Random Forest Mean Accuracy:  0.9021087672452159\n",
      "For 1202 Features Random Forest Mean Accuracy:  0.9031757899421452\n",
      "For 1602 Features Random Forest Mean Accuracy:  0.9015754339118824\n",
      "Highest score value: 0.9042428126390745\n"
     ]
    }
   ],
   "source": [
    "#Call the feature selection method\n",
    "new_class = RandomForestClassifier(n_estimators=40)\n",
    "rand_for = \"Random Forest\"\n",
    "feature_select_embedded(ran_for,new_class,rand_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(n_estimators=40),\n",
       "             param_grid=[{&#x27;n_estimators&#x27;: [40, 100, 150, 200]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(n_estimators=40),\n",
       "             param_grid=[{&#x27;n_estimators&#x27;: [40, 100, 150, 200]}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=40)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=40)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(n_estimators=40),\n",
       "             param_grid=[{'n_estimators': [40, 100, 150, 200]}])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#By finding the best feature number calculate new training and test data and fit train data into the instance of Grid Search class\n",
    "features = []\n",
    "for importance, name in sorted(zip(ran_for.feature_importances_, df.drop('target',axis=1).columns),reverse=True)[:402]:\n",
    "    features.append(name)\n",
    "x_feature = train_df[features]\n",
    "x_feature_test = test_df[features]\n",
    "\n",
    "#Apply grid search to find best hyperparameter, (because it takes lots of time to run the code I am just using 1 parameter)\n",
    "param_grid = [\n",
    "  { 'n_estimators': [40,100,150,200], \n",
    "  },\n",
    " ]\n",
    "clf = GridSearchCV(ran_for, param_grid, cv=5)   \n",
    "clf.fit(x_feature, train_df['target'])  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, test set score was 0.9064 but now it is 0.908 by using the n_estimators = 150. It improved the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter for 5 fold cross validation: {'n_estimators': 150}\n",
      "Best score for a 5 fold cross validation: 0.9063765020026702\n",
      "Test set score after CV:  0.908\n"
     ]
    }
   ],
   "source": [
    "print('Best parameter for 5 fold cross validation:',clf.best_params_)\n",
    "print('Best score for a 5 fold cross validation:',clf.best_score_)\n",
    "print('Test set score after CV: ', accuracy_score(test_df['target'],clf.predict(x_feature_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score:  0.4144\n"
     ]
    }
   ],
   "source": [
    "#Create an instance of the class SVC, which will represent the SVM\n",
    "#I made C = 3 to make test score small\n",
    "svm = SVC(C=3)\n",
    "svm.fit(train_df.drop('target', axis=1), train_df['target'])  \n",
    "print('Test set score: ', accuracy_score(test_df['target'], svm.predict(test_df.drop('target',axis=1))))   # tree.score(test_df.drop('target',axis=1), test_df['target'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that using cross validation does help again.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores:  [0.41466667 0.404      0.41733333 0.40266667 0.4058745 ]\n",
      "Avg Acc:  0.40890823319982206  std dev:  0.00593958441915745  max:  0.41733333333333333\n"
     ]
    }
   ],
   "source": [
    "cross_val(svm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that without feature selection mean cross validation score was 0.40890823319982206. Morever, with feature selection best mean cross validation score is 0.5993659101023587 which has feature value of 802. We can observe a good increaase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 2 Features SVM Mean Accuracy:  0.43612033822874946\n",
      "For 402 Features SVM Mean Accuracy:  0.5740229639519359\n",
      "For 802 Features SVM Mean Accuracy:  0.5993659101023587\n",
      "For 1202 Features SVM Mean Accuracy:  0.40890823319982206\n",
      "For 1602 Features SVM Mean Accuracy:  0.40890823319982206\n",
      "Highest score value: 0.5993659101023587\n"
     ]
    }
   ],
   "source": [
    "##Define a method for calculating feature selection for mutual information \n",
    "#because wrapper method takes much more time than filter method I couldn't use it but it is more accurate to use wrapper method for SVM for instance\n",
    "#Select the best feature by their average k fold cross validation score values\n",
    "def feature_selection_mutual(class_algorithm,class_name):\n",
    "  ks = [i for i in range(2, df.drop('target',axis=1).shape[1],400)]\n",
    "  arr = []\n",
    "\n",
    "  for k in ks:\n",
    "    select = GenericUnivariateSelect(score_func=mutual_info_classif, mode=\"k_best\", param=k)\n",
    "    X_k = select.fit_transform(train_df.drop('target', axis=1), train_df['target'])\n",
    "    score = cross_val_score(class_algorithm, X_k, train_df['target'], cv=5).mean()\n",
    "    print(f\"For {k} Features {class_name} Mean Accuracy: \", score)\n",
    "    arr.append( score )\n",
    "  arr.sort(reverse=True)\n",
    "  print(\"Highest score value:\",arr[0])\n",
    "\n",
    "svm_name = \"SVM\"\n",
    "feature_selection_mutual(svm,svm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(C=3), param_grid=[{&#x27;C&#x27;: [1, 3, 5, 9]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(C=3), param_grid=[{&#x27;C&#x27;: [1, 3, 5, 9]}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=3)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=3)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(C=3), param_grid=[{'C': [1, 3, 5, 9]}])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#By finding the best feature number calculate new training and test data and fit train data into the instance of Grid Search class\n",
    "svm_new = SVC(C=3)\n",
    "select = GenericUnivariateSelect(score_func=mutual_info_classif, mode=\"k_best\", param=802)\n",
    "select.fit(train_df.drop('target', axis=1), train_df['target'])\n",
    "X_train = select.transform(train_df.drop('target', axis=1))\n",
    "X_test = select.transform(test_df.drop('target', axis=1))\n",
    "\n",
    "#Apply grid search to find best hyperparameter, (because it takes lots of time to run the code I am just using 1 parameter)\n",
    "param_grid = [\n",
    "  {\n",
    "   'C': [1,3, 5, 9]\n",
    "   },\n",
    " ]\n",
    "clf = GridSearchCV(svm_new, param_grid, cv=5)   \n",
    "clf.fit(X_train, train_df['target'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, test set score was 0.4144 but now it is 0.6928 by using the C = 9. It improved the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter for 5 fold cross validation: {'C': 9}\n",
      "Best score for a 5 fold cross validation: 0.6380414775255897\n",
      "Test set score after CV:  0.6928\n"
     ]
    }
   ],
   "source": [
    "print('Best parameter for 5 fold cross validation:',clf.best_params_)\n",
    "print('Best score for a 5 fold cross validation:',clf.best_score_)\n",
    "print('Test set score after CV: ', accuracy_score(test_df['target'],clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score:  0.6824\n"
     ]
    }
   ],
   "source": [
    "#Create an instance of the class K Neighbors Classifier, which will represent the knn\n",
    "#I made n_neighbors=1, p = 2 to make test score small\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=1, p=2)\n",
    "knn_classifier.fit(train_df.drop('target', axis=1), train_df['target'])  \n",
    "print('Test set score: ', accuracy_score(test_df['target'], knn_classifier.predict(test_df.drop('target',axis=1))))   # tree.score(test_df.drop('target',axis=1), test_df['target'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that using cross validation does help again.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores:  [0.68133333 0.66533333 0.67066667 0.672      0.69158879]\n",
      "Avg Acc:  0.6761844236760124  std dev:  0.00926829893171791  max:  0.6915887850467289\n"
     ]
    }
   ],
   "source": [
    "cross_val(knn_classifier)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that without feature selection mean cross validation score was 0.6761844236760124. Morever, with feature selection best mean cross validation score is 0.7311305740987983 which has feature value of 1202. We can observe a good increaase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 2 Features KNN Mean Accuracy:  0.6833865598575879\n",
      "For 402 Features KNN Mean Accuracy:  0.7025965287049398\n",
      "For 802 Features KNN Mean Accuracy:  0.650841121495327\n",
      "For 1202 Features KNN Mean Accuracy:  0.7311305740987983\n",
      "For 1602 Features KNN Mean Accuracy:  0.7201979528259902\n",
      "Highest score value: 0.7311305740987983\n"
     ]
    }
   ],
   "source": [
    "knn_name = \"KNN\"\n",
    "feature_selection_mutual(knn_classifier,knn_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(n_neighbors=1),\n",
       "             param_grid=[{&#x27;n_neighbors&#x27;: [1, 2, 3, 4], &#x27;p&#x27;: [1, 2, 5]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(n_neighbors=1),\n",
       "             param_grid=[{&#x27;n_neighbors&#x27;: [1, 2, 3, 4], &#x27;p&#x27;: [1, 2, 5]}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(n_neighbors=1),\n",
       "             param_grid=[{'n_neighbors': [1, 2, 3, 4], 'p': [1, 2, 5]}])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#By finding the best feature number calculate new training and test data and fit train data into the instance of Grid Search class\n",
    "knn_classifier_new = KNeighborsClassifier(n_neighbors=1, p=2)\n",
    "select = GenericUnivariateSelect(score_func=mutual_info_classif, mode=\"k_best\", param=1202)\n",
    "select.fit(train_df.drop('target', axis=1), train_df['target'])\n",
    "X_train = select.transform(train_df.drop('target', axis=1))\n",
    "X_test = select.transform(test_df.drop('target', axis=1))\n",
    "\n",
    "#Apply grid search to find best hyperparameter\n",
    "param_grid = [\n",
    "  { 'n_neighbors': [1, 2, 3, 4], \n",
    "    'p': [1, 2, 5]},\n",
    " ]\n",
    "clf = GridSearchCV(knn_classifier_new, param_grid, cv=5)   \n",
    "clf.fit(X_train, train_df['target'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, test set score was 0.6824 but now it is 0.848 by using the n_neighbors = 4, p = 1. It improved the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter for 5 fold cross validation: {'n_neighbors': 4, 'p': 1}\n",
      "Best score for a 5 fold cross validation: 0.8327547841566533\n",
      "Test set score after CV:  0.848\n"
     ]
    }
   ],
   "source": [
    "print('Best parameter for 5 fold cross validation:',clf.best_params_)\n",
    "print('Best score for a 5 fold cross validation:',clf.best_score_)\n",
    "print('Test set score after CV: ', accuracy_score(test_df['target'],clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score:  0.4712\n"
     ]
    }
   ],
   "source": [
    "#Create an instance of the class Guassian Naive Bayes, which will represent the naive bayes\n",
    "#I made var_smoothing default to make test score small\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_df.drop('target', axis=1), train_df['target'])\n",
    "print('Test set score: ', accuracy_score(test_df['target'], gnb.predict(test_df.drop('target',axis=1))))   # tree.score(test_df.drop('target',axis=1), test_df['target'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that using cross validation does help again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores:  [0.508      0.45866667 0.464      0.48933333 0.47396529]\n",
      "Avg Acc:  0.4787930574098799  std dev:  0.017951915945319825  max:  0.508\n"
     ]
    }
   ],
   "source": [
    "cross_val(gnb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that without feature selection mean cross validation score was 0.4787930574098799. Morever, with feature selection best mean cross validation score is 0.49586648865153543 which has feature value of 1202. We can observe an increaase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 2 Features GNB Mean Accuracy:  0.14937676902536717\n",
      "For 402 Features GNB Mean Accuracy:  0.39557703604806405\n",
      "For 802 Features GNB Mean Accuracy:  0.437720694259012\n",
      "For 1202 Features GNB Mean Accuracy:  0.49586648865153543\n",
      "For 1602 Features GNB Mean Accuracy:  0.47666079216733426\n",
      "Highest score value: 0.49586648865153543\n"
     ]
    }
   ],
   "source": [
    "gnb_name = \"GNB\"\n",
    "feature_selection_mutual(gnb,gnb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.31...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.31...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.31...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#By finding the best feature number calculate new training and test data and fit train data into the instance of Grid Search class\n",
    "gnb_new = GaussianNB()\n",
    "select = GenericUnivariateSelect(score_func=mutual_info_classif, mode=\"k_best\", param=1202)\n",
    "select.fit(train_df.drop('target', axis=1), train_df['target'])\n",
    "X_train = select.transform(train_df.drop('target', axis=1))\n",
    "X_test = select.transform(test_df.drop('target', axis=1))\n",
    "\n",
    "#Apply grid search to find best hyperparameter, (because it takes lots of time to run the code I am just using 1 parameter)\n",
    "param_grid= {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "clf = GridSearchCV(gnb_new, param_grid, cv=5)   \n",
    "clf.fit(X_train, train_df['target'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, test set score was 0.4712 but now it is 0.5856 by using the var_smoothing = 6.579332246575682e-07. It improved the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter for 5 fold cross validation: {'var_smoothing': 6.579332246575682e-07}\n",
      "Best score for a 5 fold cross validation: 0.5673513128615932\n",
      "Test set score after CV:  0.5856\n"
     ]
    }
   ],
   "source": [
    "print('Best parameter for 5 fold cross validation:',clf.best_params_)\n",
    "print('Best score for a 5 fold cross validation:',clf.best_score_)\n",
    "print('Test set score after CV: ', accuracy_score(test_df['target'],clf.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use majority voting to see if it would be better to create new classifier from extisting classifiers. I will use the classification methods that has the same feature values. And first fit them with their best parameter values that I have found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For majority voting I am going to use two classification methods (K Nearest Neighborhood and Naive Bayes)  \n",
    "#From the feature selection above we can observe that they show the best performance for the same value of features\n",
    "#I will also use the above Grid Search best parameter results and we will se if score result will increase or not\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "classifiers = [GaussianNB(var_smoothing=6.579332246575682e-07), KNeighborsClassifier(n_neighbors=4, p=1)]\n",
    "names = [\"Naive Bayes\" ,\"4-NN\"]\n",
    "classifiers.append( VotingClassifier([ (type(x).__name__, x) for x in classifiers ]) )\n",
    "names.append(\"Vote(NB,5-NN)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula of voting classifier is: $$h_\\text{ensemble}(x) = \\frac{1}{z} \\sum_{i=1}^z h_i(x)$$ Because 4NN score is much more than NB score when we take voting classifier ensemble of this 2 classification methods the score result becomes less than the score result of 4NN. Thus, in this case it is better to choose 4NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Naive Bayes 0.452\n",
      "\t 4-NN 0.8152\n",
      "\t Vote(NB,5-NN) 0.6712\n"
     ]
    }
   ],
   "source": [
    "for model, m_name in zip(classifiers, names):\n",
    "  model.fit(X_train, train_df['target'])\n",
    "  print(\"\\t\", m_name, accuracy_score(test_df['target'], model.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result is better to use Random Forest classification method because it is accuracy is about 90% since the beginning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16e8d73999c029d353dc6c0ea31bc8db97d3e130d5912003345cf33b71c7e559"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
